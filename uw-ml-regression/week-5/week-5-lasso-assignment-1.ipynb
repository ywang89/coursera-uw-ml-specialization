{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Week 5: LASSO Assignment 1\n",
    "\n",
    "In this assignment, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second assignment, you will implement your own LASSO solver, using coordinate descent.\n",
    "\n",
    "Load the sales dataset using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv('../week-3/kc_house_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new features by performing following transformation on inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big.\n",
    "\n",
    "Using the entire house dataset, learn regression weights using an L1 penalty of `5e2`. Make sure to add `normalize=True` when creating the Lasso object. Refer to the following code snippet for the list of features.\n",
    "\n",
    "**Note**. From here on, the list `all_features` refers to the list defined in this snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=500.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model  # using scikit-learn\n",
    "\n",
    "all_features = ['bedrooms', 'bedrooms_square','bathrooms', 'sqft_living', \n",
    "                'sqft_living_sqrt','sqft_lot', 'sqft_lot_sqrt', 'floors', \n",
    "                'floors_square', 'waterfront', 'view', 'condition', \n",
    "                'grade', 'sqft_above', 'sqft_basement', 'yr_built', \n",
    "                'yr_renovated']\n",
    "\n",
    "model_all = linear_model.Lasso(alpha=5e2, normalize=True) # set parameters\n",
    "model_all.fit(sales[all_features], sales['price']) # learn weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Quiz Question***: Which features have been chosen by LASSO, i.e. which features were assigned nonzero weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sqft_living', 'view', 'grade'], dtype='<U16')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_1 = (model_all.coef_ != 0)\n",
    "filter_1\n",
    "\n",
    "np_all_features = np.array(all_features)\n",
    "np_all_features[filter_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets. Download the provided csv files containing training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('../week-3/wk3_kc_house_test_data.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('../week-3/wk3_kc_house_train_data.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('../week-3/wk3_kc_house_valid_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to create the 4 features as we did in #1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['sqft_living_sqrt'] = testing['sqft_living'].apply(sqrt)\n",
    "testing['sqft_lot_sqrt'] = testing['sqft_lot'].apply(sqrt)\n",
    "testing['bedrooms_square'] = testing['bedrooms']*testing['bedrooms']\n",
    "testing['floors_square'] = testing['floors']*testing['floors']\n",
    "\n",
    "training['sqft_living_sqrt'] = training['sqft_living'].apply(sqrt)\n",
    "training['sqft_lot_sqrt'] = training['sqft_lot'].apply(sqrt)\n",
    "training['bedrooms_square'] = training['bedrooms']*training['bedrooms']\n",
    "training['floors_square'] = training['floors']*training['floors']\n",
    "\n",
    "validation['sqft_living_sqrt'] = validation['sqft_living'].apply(sqrt)\n",
    "validation['sqft_lot_sqrt'] = validation['sqft_lot'].apply(sqrt)\n",
    "validation['bedrooms_square'] = validation['bedrooms']*validation['bedrooms']\n",
    "validation['floors_square'] = validation['floors']*validation['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each l1_penalty in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "\n",
    "* Learn a model on TRAINING data using the specified l1_penalty. Make sure to specify normalize=True in the constructor\n",
    "\n",
    "* Compute the RSS on VALIDATION for the current model (print or save the RSS)\n",
    "\n",
    "Report which L1 penalty produced the lower RSS on VALIDATION.\n",
    "\n",
    "***Quiz Question***: Which was the best value for the l1_penalty, i.e. which value of l1_penalty produced the lowest RSS on VALIDATION data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398213327300134.94\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "l1_penalty = np.logspace(1, 7, num=13)\n",
    "\n",
    "def get_lowest_rss(l1_penalty, training, validation):\n",
    "    for i in range(len(l1_penalty)):    \n",
    "        model = linear_model.Lasso(alpha=l1_penalty[i], normalize=True)\n",
    "        model.fit(X=training.loc[:, all_features], y=training['price'])\n",
    "        pred_price = model.predict(validation.loc[:, all_features])\n",
    "        rss = np.sum((pred_price - validation['price']) ** 2)\n",
    "        \n",
    "        if i == 0:\n",
    "            lowest_rss = rss\n",
    "            best_l1_penalty = l1_penalty[i]\n",
    "            best_model = model\n",
    "        \n",
    "        if rss < lowest_rss:\n",
    "            lowest_rss = rss\n",
    "            best_l1_penalty = l1_penalty[i]\n",
    "            best_model = model\n",
    "    \n",
    "    return (lowest_rss, best_l1_penalty, best_model)\n",
    "\n",
    "lowest_rss, best_l1_penalty, best_model = get_lowest_rss(l1_penalty, training, validation)\n",
    "\n",
    "print(lowest_rss)\n",
    "print(best_l1_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have selected an L1 penalty, compute the RSS on TEST data for the model with the best L1 penalty.\n",
    "\n",
    "***Quiz Question***: Using the best L1 penalty, how many nonzero weights do you have? Count the number of nonzero coefficients first, and add 1 if the intercept is also nonzero. A succinct way to do this is as below where `model` is an instance of `linear_model.Lasso`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(best_model.coef_) + np.count_nonzero(best_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.61445628e+04,  3.73245384e+02,  5.08412433e+04,  6.17853560e+02,\n",
       "       -4.44113549e+04,  7.85623065e-01, -7.01194765e+02, -0.00000000e+00,\n",
       "        5.01420046e+03,  6.19488752e+05,  3.80418557e+04,  2.49987718e+04,\n",
       "        1.28716235e+05,  0.00000000e+00,  0.00000000e+00, -3.29383118e+03,\n",
       "        1.00573209e+01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them.\n",
    "\n",
    "You are going to implement a simple, two phase procedure to achieve this goal:\n",
    "\n",
    "* Explore a large range of ‘l1_penalty’ values to find a narrow region of ‘l1_penalty’ values where models are likely to have the desired number of non-zero weights.\n",
    "* Further explore the narrow region you found to find a good value for ‘l1_penalty’ that achieves the desired sparsity. Here, we will again use a validation set to choose the best value for ‘l1_penalty’.\n",
    "\n",
    "Assign 7 to the variable ‘max_nonzeros’.\n",
    "\n",
    "### Exploring large range of l1_penalty\n",
    "\n",
    "For `l1_penalty` in `np.logspace(1, 4, num=20)`:\n",
    "\n",
    "* Fit a regression model with a given `l1_penalty` on TRAIN data. Add `alpha=l1_penalty` and `normalize=True` to the parameter list.\n",
    "* Extract the weights of the model and count the number of nonzeros. Take account of the intercept as we did in #8, adding 1 whenever the intercept is nonzero. Save the number of nonzeros to a list.\n",
    "\n",
    "Out of this large range, we want to find the two ends of our desired narrow range of l1_penalty. At one end, we will have l1_penalty values that have too few non-zeros, and at the other end, we will have an l1_penalty that has too many non-zeros.\n",
    "\n",
    "More formally, find:\n",
    "\n",
    "* The largest l1_penalty that has more non-zeros than ‘max_nonzeros’ (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest l1_penalty that has fewer non-zeros than ‘max_nonzeros’ (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "Hint: there are many ways to do this, e.g.:\n",
    "\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of l1_penalty and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left bound, l1_penalty_min: 127.43; non-zero count: 10; j: 7\n",
      "right bound, l1_penalty_max: 263.67; non-zero count: 6; j: 9\n"
     ]
    }
   ],
   "source": [
    "max_nonzeros = 7\n",
    "\n",
    "l1_penalty = np.logspace(1, 4, num=20)\n",
    "non_zeros = []\n",
    "\n",
    "for i in range(len(l1_penalty)):\n",
    "    model = linear_model.Lasso(alpha=l1_penalty[i], normalize=True)\n",
    "    model.fit(X=training.loc[:, all_features], y=training['price'])\n",
    "    non_zeros.append(np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_))\n",
    "    \n",
    "for j in range(1, len(non_zeros)-2):\n",
    "    if non_zeros[j] > max_nonzeros and non_zeros[j+1] <= max_nonzeros:\n",
    "        l1_penalty_min = l1_penalty[j]\n",
    "        non_zero_cnt_left = non_zeros[j]\n",
    "        j_left = j\n",
    "    if non_zeros[j] < max_nonzeros and non_zeros[j-1] >= max_nonzeros:\n",
    "        l1_penalty_max = l1_penalty[j]\n",
    "        non_zero_cnt_right = non_zeros[j]\n",
    "        j_right = j\n",
    "        \n",
    "print('left bound, l1_penalty_min: %.2f; non-zero count: %d; j: %d' % (l1_penalty_min, non_zero_cnt_left, j_left))\n",
    "print('right bound, l1_penalty_max: %.2f; non-zero count: %d; j: %d' % (l1_penalty_max, non_zero_cnt_right, j_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHGJJREFUeJzt3Xl4FGW6NvD76c6+kASSsCSRsEhYI0uzBdcj+qGgsoiIgjqCCOiMo/ONR2ccZxwZdWY849GjgICK4yAqmwug4s6RANqArGFfg4QEAgkQkpDkOX+QM5/DByTp7vRbVX3/rouLpLroui9euCmq33pLVBVERGR/LtMBiIgoMFjoREQOwUInInIIFjoRkUOw0ImIHIKFTkTkECx0IiKHYKETETkEC52IyCFY6EREDhEWzIMlJydrZmZmMA9JRGR7a9asOaKqKXXtF9RCz8zMhNfrDeYhiYhsT0T21Wc/XnIhInIIFjoRkUOw0ImIHIKFTkTkECx0IiKHYKETETlEUKct+irvUCnyj502HcMvbVNi0S4lznQMInIwWxT626v3461V9ZqGaVnhbsGyh69Cm+RY01GIyKFsUegTr26HUb0zTMfwWVllNX72xnd4ZmkeZt7lMR2HiBzKFoWelhiNtMRo0zH8Mvma9vjrp9uQu+sIctolm45DRA7ED0WDZNzlbZCWGI2nF+ehukZNxyEiB2KhB0lUuBuP3dAReYdKMc97wHQcInIgFnoQDcluiV6tk/D8su04WVFlOg4ROQwLPYhEBL8b0hlHTlZg6lc7TcchIodhoQdZ94xEDOuRhlnf7sGB4jLTcYjIQVjoBjw6KAsuAZ77ZKvpKETkICx0A1omRGPCle2wZMMhePcWm45DRA7BQjdk4lVt0bxJJJ5evAU1nMZIRAFQZ6GLyOsiUigim87z2v8VERUR3inTQDERYXj0/3TE+vwSfLD+oOk4ROQA9TlDnw1g0LkbRSQDwHUA9gc4U8gY1iMN2ekJ+PPH21BWyWmMROSfOgtdVZcDON+F3hcAPAqA1wt85HIJnhjcGQWl5ZixfLfpOERkcz5dQxeRmwEcVNX1Ac4Tcvq0aYrB3Vri1W92o6Ck3HQcIrKxBhe6iMQA+C2AJ+u5/wQR8YqIt6ioqKGHCwmP3dAR1TWKv3zKaYxE5DtfztDbAWgDYL2I7AWQDmCtiLQ4386qOkNVParqSUlJ8T2pg2U0jcG9l7fBwrUHsSH/uOk4RGRTDS50Vd2oqqmqmqmqmQDyAfRU1YKApwshD1zTDslxEfjjR1ugyo8liKjh6jNtcS6AlQCyRCRfRMY1fqzQEx8Vjl9dnwXvvmNYupH/NhJRw9VnlstoVW2pquGqmq6qr53zeqaqHmm8iKHjNk8GOraIx7Mf56H8TLXpOERkM7xT1ELcrrOrMeYfO403Vuw1HYeIbIaFbjED2idjYKdUvPLVThSdqDAdh4hshIVuQb+5sRPKz1Tjb59tMx2FiGyEhW5BbVPicFf/TLz7/QHkHSo1HYeIbIKFblEPXXspmkSHY8oSTmMkovphoVtUQkw4fnntpVix8yi+yCs0HYeIbICFbmF39muNdimx+NPSPFRW1ZiOQ0QWx0K3sHC3C08M7ow9R07hrVX7TMchIotjoVvc1VkpuOLSZLzw2Xas3n3UdBwisjAWusWJCP48IhvNm0Ri7GvfYfGGH01HIiKLYqHbQKvEaCyYlIPLMhLw4NvrMHP5bs58IaL/DwvdJhJjIvDWuL64sVsL/GlpHp76aAuq+XBpIvoJFrqNRIW78fLonhh3eRvMzt2LyXPWcBEvIvonFrrNuGoX8PrdkM5YtuUw7pi5CsWnKk3HIiILYKHb1LjL2+CVO3pi04+luHVaLvYfLTMdiYgMY6Hb2I3dWmLO+L4oLqvE8GkrsP4AH19HFMpY6DbXO7Mp5k/MQVS4G7fPWIUvtx42HYmIDGGhO0D71DgsnJyD9qlxGP+mF2+v3m86EhEZwEJ3iNT4KLwzoR+u7JCC3yzaiOc/3ca56kQhpj4PiX5dRApFZNNPtv1VRLaKyAYRWSQiiY0bk+ojNjIMs+7y4PbeGXj5q5341bz1XNSLKITU5wx9NoBB52z7DEBXVc0GsB3A4wHORT4Kc7vw7PBueOS6Dli49iDunf09SsvPmI5FREFQZ6Gr6nIAxedsW6aqVbXfrgKQ3gjZyEcigl9ceyn+ems2Vu0+itumr0RBSbnpWETUyAJxDf1eAB8H4H0owEZ6MvD6Pb1xoLgMw6auwLaCE6YjEVEj8qvQReS3AKoAzLnIPhNExCsi3qKiIn8ORz64skMK3pvYH9U1ilun5yJ31xHTkYiokfhc6CJyN4AhAO7Ui0ynUNUZqupRVU9KSoqvhyM/dGmVgEUPDECLJlG4+/Xv8MEPB01HIqJG4FOhi8ggAP8O4GZV5T3nNpCWGI35E3PQ85IkPPTOD5j29S5OayRymPpMW5wLYCWALBHJF5FxAF4GEA/gMxH5QUSmN3JOCoCEmHD8fVwf3HRZK/z5k6148oPNXIKXyEHC6tpBVUefZ/NrjZCFgiAyzI0XR3VHq4QovLp8NwpKy/HS7T0QHeE2HY2I/MQ7RUOQyyV4/MZOeOrmLvg87zBGz1yFoycrTMciIj+x0EPY3TmZmHZnL+QdKsWIabnYe+SU6UhE5AcWeogb1LUF3r6vH0pOn8HwablYt/+Y6UhE5CMWOqFX6yQsmJSDuMgwjJ65Cp9t4RK8RHbEQicAQNuUs0vwZjWPx/1vefHWyr2mIxFRA7HQ6Z+S4yIxd0I/XJOVit99sBnPfbwVNZzWSGQbLHT6FzERYXh1bC/c2fcSTP9mFx5+7wdUVFWbjkVE9VDnPHQKPWFuF6YM7Yq0pGj85ZNtKCytwPSxvZAQHW46GhFdBM/Q6bxEBJOvbo8XRl0G775ijJyeix+PnzYdi4gugoVOFzWsRzre/FkfHDpejmFTVyDvUKnpSER0ASx0qlNO+2TMm9QfAsHI6Svx7Q4uwUtkRSx0qpeOLZpg0QM5SEuMxj1vfIeFa/NNRyKic7DQqd5aJkRj3qT+6NOmKR55bz1e/nIHl+AlshAWOjVIk6hwzP5ZHwzt3grPL9uO3yzahKrqGtOxiAictkg+iAhz4YVR3dEqMRpTv96Fw6Xl+K/RPRAbyT9ORCbxDJ18IiJ4dFBHTBnaFV9vK8TomatQdIJL8BKZxEInv4zp1xozxnqw4/BJDJ+2AruKTpqORBSyWOjkt4Gdm2PuhH4oq6jGiGm5WLOv2HQkopDEQqeA6J6RiIWTc5AUE4E7Zq7GJ5sOmY5EFHLq85Do10WkUEQ2/WRbUxH5TER21P6c1LgxyQ5aN4vFgkk56NyqCSbNWYs3VuwxHYkopNTnDH02gEHnbHsMwBeqeimAL2q/J0LT2Ai8Pb4fruvUHE99tAVTFm/hErxEQVJnoavqcgDnXhS9BcCbtV+/CWBogHORjUVHuDFtTC/c3b81Zn27Bz9/Zx3Kz3AJXqLG5uvE4eaqeggAVPWQiKQGMBM5gNsl+MPNXZCWFI1nlm7F0ZMVmDO+H9wuMR2NyLEa/UNREZkgIl4R8RYVFTX24chCRAQTrmyHp2/pglW7i/HtTi7qRdSYfC30wyLSEgBqfy680I6qOkNVParqSUlJ8fFwZGe39c5AYkw45nkPmI5C5Gi+FvqHAO6u/fpuAB8EJg45UWSYG0O7p2HZlsMoKTtjOg6RY9Vn2uJcACsBZIlIvoiMA/AcgOtEZAeA62q/J7qgW3ulo7KqBh9u+NF0FCLHqvNDUVUdfYGXrg1wFnKwLq2aoGOLeMz3HsDYfq1NxyFyJN4pSkEhIhjpycD6/BJsP3zCdBwiR2KhU9AM7d4KYS7hh6NEjYSFTkHTLC4S13ZKxaJ1B3GGD8UgCjgWOgXVyF4ZOHKyEt9s4z0JRIHGQqeguiorBclxEZi3hpddiAKNhU5BFe52YViPNHyRV4ijJ/mEI6JAYqFT0I30ZKCqRvH+D5yTThRILHQKug7N43FZegLmeQ9AlUvrEgUKC52MuNWTga0FJ7D5x1LTUYgcg4VORtyc3QoRYS7MX5NvOgqRY7DQyYiEmHBc37k53v/hICqq+PALokBgoZMxIz0ZOF52Bl/kXXD1ZSJqABY6GXN5+2S0TIjiUgBEAcJCJ2PcLsHwnmn4ZnsRDpeWm45DZHssdDJqRM901CiwaN1B01GIbI+FTka1TYmDp3US56QTBQALnYwb6UnHrqJTWHfguOkoRLbGQifjBme3QnS4G/O8nJNO5A8WOhkXFxmGG7q1wOL1P+J0JeekE/nKr0IXkYdFZLOIbBKRuSISFahgFFpG9srAiYoqLNtSYDoKkW35XOgikgbgFwA8qtoVgBvA7YEKRqGlb5umSE+K5mUXIj/4e8klDEC0iIQBiAHA9VDJJy6X4NZe6Vix6wgOHj9tOg6RLflc6Kp6EMDzAPYDOASgRFWXBSoYhZ4RPdOhCizggl1EPvHnkksSgFsAtAHQCkCsiIw5z34TRMQrIt6iIj5Hki4so2kMcto1w/w1+aip4Zx0ooby55LLQAB7VLVIVc8AWAgg59ydVHWGqnpU1ZOSkuLH4SgUjPSkY39xGb7bW2w6CpHt+FPo+wH0E5EYEREA1wLIC0wsClWDurREXGQY10kn8oE/19BXA5gPYC2AjbXvNSNAuShERUe4MSS7JZZuPIRTFVWm4xDZil+zXFT196raUVW7qupYVeVj3MlvIz3pKKusxpKNh0xHIbIV3ilKltPzkiS0TYnFfM5JJ2oQFjpZjsjZOenf7S3G3iOnTMchsg0WOlnS8B7pcAmwYC3P0onqi4VOltQiIQpXXJqCBWvyUc056UT1wkInyxrpScePJeXI3XXEdBQiW2Chk2UN7NQcCdHhXLCLqJ5Y6GRZUeFu3NK9FT7dXICS02dMxyGyPBY6WdrIXhmoqKrB4g1cyJOoLix0srSuaU2Q1Twe7/GyC1GdWOhkaSKC0X0ysP7AcTz10WbOeCG6iDDTAYjqclf/TOwvPo3XV+xBQUk5XhjVHVHhbtOxiCyHZ+hkeS6X4MmbOuOJwZ3wyeYCjJm1GsdOVZqORWQ5LHSyjfFXtMXLo3tiw8ESjJieiwPFZaYjEVkKC51sZXB2S8wZ3xdHT1Zi2NQV2JB/3HQkIstgoZPt9M5sigWTchAZ5saoV1fhq62FpiMRWQILnWypfWocFj2Qg3apsRj/dy/mfrffdCQi41joZFup8VF4d0J/XN4+GY8v3Ij/WLYNqpzWSKGLhU62FhsZhll3ezDKk4H/+nInfjVvPSqrakzHIjKC89DJ9sLdLjw3ohtaJUbjhc+3o7C0AtPG9ER8VLjpaERBxTN0cgQRwUMDL8Vfb83Gqt1HMXL6ShSUlJuORRRUfhW6iCSKyHwR2SoieSLSP1DBiHwx0pOB1+7pjQPFZRg+dQW2Hz5hOhJR0Ph7hv4igE9UtSOAywDk+R+JyD9XdUjBu/f3R1WNYsS0XKzcddR0JKKgEF9nBYhIEwDrAbTVer6Jx+NRr9fr0/GIGir/WBnueeN77D9ahidv6oyOLeKNZUmMiUD71Dhjxyd7E5E1quqpaz9/PhRtC6AIwBsichmANQAeUlU+pp0sIT0pBgsm5uC+t7x44v1NpuPg4YEd8Itr20NETEchh/LnDN0DYBWAAaq6WkReBFCqqr87Z78JACYAwCWXXNJr3759fkYmapjKqhqs2XcMVTXmpjMuWnsQC9cdxChPBqYM64pwN+cjUP0F4ww9H0C+qq6u/X4+gMfO3UlVZwCYAZy95OLH8Yh8EhHmQv92zYxmuLx9MtKTovHSlztRUFqOqXf2RGwkZw1TYPl8mqCqBQAOiEhW7aZrAWwJSCoihxERPHJ9Fp4d3g3f7jyCUTNWovAEp1VSYPn7/76fA5gjIhsAdAfwjP+RiJxrdJ9LMOsuD3YVnsKwV3Kxs5DTKilw/Cp0Vf1BVT2qmq2qQ1X1WKCCETnVNR1T8e79/VBRVY0R01biuz3FpiORQ/CTGSIDstMTsWjyADSLi8CY11ZjyYZDpiORA7DQiQzJaHp2WmV2WgIenLsWs/57t+lIZHMsdCKDkmIj8I/xfTGoSwtMWZKHpz7ajOoaTgYj37DQiQyLCnfj5Tt64t4BbfDGir148O21KD9TbToW2RALncgC3C7Bkzd1xhODO+GTzQUYM2s1jp2qNB2LbIaFTmQh469oi5dH98SGgyUYMT0XB4rLTEciG2GhE1nM4OyW+Me4vjh6shLDpq7AhvzjpiORTbDQiSyoT5umWDCpPyLD3Bj16ip8tbXQdCSyARY6kUW1T43Hogdy0C41FuP/7sWmgyWmI5HFsdCJLCw1PgpzxvVDQnQ4nl68Bb6ujkqhgYVOZHEJMeF4+LoOWL2nGJ9uPmw6DlkYC53IBkb3zkCH5nF49uM8VFRxjjqdHwudyAbC3C78dnBn7Dtahr/n8iExdH4sdCKbuKpDCq7JSsFLX+zA0ZMVpuOQBbHQiWzkt4M7oexMNV74fLvpKGRBLHQiG2mfGo8xfS/B26v3Y/thPhyD/hULnchmfjmwA+IiwzBlSZ7pKGQxLHQim0mKjcBDAztg+fYifLWNd5DS/8NCJ7Khsf1ao01yLKYs3oIz1TWm45BF+F3oIuIWkXUisjgQgYiobhFhLvzmxk7YVXQKb6/ebzoOWUQgztAfAsCLeURBNrBTKnLaNcMLn29HSdkZ03HIAvwqdBFJBzAYwKzAxCGi+hIRPDG4M0pOn8FLX+4wHYcswN8z9P8E8CgAXsQjMqBzqya4vXcG3szdi91FJ03HIcN8LnQRGQKgUFXX1LHfBBHxioi3qKjI18MR0QU8cl0WosLdeGbpVtNRyDB/ztAHALhZRPYCeAfAv4nIP87dSVVnqKpHVT0pKSl+HI6IziclPhKTr2mHz/MOI3fnEdNxyCCfC11VH1fVdFXNBHA7gC9VdUzAkhFRvd07oA3Sk6Lxx8VbUF3DNdNDFeehEzlAVLgbj9/QCVsLTmCe94DpOGRIQApdVb9W1SGBeC8i8s2N3Vqgd2YSnl+2DSfKOY0xFPEMncgh/nca45GTlZj69S7TccgAFjqRg1yWkYjhPdLw2rd7cKC4zHQcCjIWOpHD/HpQFlwCPPcJpzGGGhY6kcO0TIjGxKvaYcmGQ/h+b7HpOBRELHQiB5pwZVu0aBKFpxdvQQ2nMYYMFjqRA8VEhOHRQVnYkF+C9384aDoOBQkLncihhnZPQ3Z6Av7yyTaUVVaZjkNBwEInciiXS/DkkM4oKC3Hq9/sNh2HgiDMdAAiajyezKYYnN0Sr3y1EwvW5vv8PvFR4ZgytCt6tU4KYDoKNBY6kcP9/qbOaBYbgZMVvl92+X5vMe6YuQov3t4Dg7q2CGA6CiRRDd4n4B6PR71eb9COR0SBcfRkBca96cX6/OP4w01dcHdOpulIIUVE1qiqp679eA2diOrULC4Sc+/rh2s7NsfvP9yMZ5bmcTqkBbHQiaheoiPceHVsL4zt1xozlu/GL95Zh4qqatOx6Cd4DZ2I6s3tEvzxli5IS4rGcx9vReGJCswc60FCTLjpaASeoRNRA4kIJl7VDi/e3h3r9h/DiOm5yD/GhcCsgIVORD65pXsa3ry3Dw6XlmP41Fxs/rHEdKSQx0InIp/ltEvG/Ik5CHMJbpu+Esu380HwJrHQicgvWS3isXDyAGQ0jcG9s7/nI/AMYqETkd9aJERh3sT+6Ne2GX49fwNe/HwHgnmPC53lc6GLSIaIfCUieSKyWUQeCmQwIrKX+KhwvH5PbwzvmYYXPt+OxxZsxJnqGtOxQoo/0xarAPxKVdeKSDyANSLymapuCVA2IrKZiDAX/mPkZUhPjMZLX+5EQWk5pt7ZE7GRnCEdDD6foavqIVVdW/v1CQB5ANICFYyI7ElE8Mj1WXh2eDd8u/MIRs1YicIT5aZjhYSAXEMXkUwAPQCsDsT7EZH9je5zCWbd5cGuwlMY9koudhaeMB3J8fwudBGJA7AAwC9VtfQ8r08QEa+IeIuKOKWJKJRc0zEV797fDxVVNRgxbSWfcdrI/Cp0EQnH2TKfo6oLz7ePqs5QVY+qelJSUvw5HBHZUHZ6IhZNzkGzuAjcOWs1lmw4ZDqSY/kzy0UAvAYgT1X/FrhIROQ0GU1jsGBiDrqlJeDBuWsx67/5BKXG4M8Z+gAAYwH8m4j8UPvjxgDlIiKHSYqNwJzxfTGoSwtMWZKHP360hUvwBpjPc4lU9VsAEsAsRORwUeFuvHxHT0xZsgWvr9iDgtLT+Ntt3REV7jYdzRF4pygRBZXbJfj9TV3wxOBOWLqxAGNmrcaxU5WmYzkCC52IjBh/RVu8fEcPbMgvwYjpuThQzCV4/cVCJyJjhmS3wj/G98XRk5UYNjUXG/O5BK8/WOhEZFSfNk2xYFJ/RIa5MGrGSny1rdB0JNtioRORce1T47Focg7aJMdi/JtevPPdftORbImFTkSWkNokCu/e3x8D2ifjsYUb8bfPtnMJ3gZioRORZcRFhuG1uz0Y2SsdL32xA7+ev4FL8DYA17QkIksJd7vwl1uzkZYUjf/8fAcO1y7BGx8Vbjqa5bHQichyRAS/HNgBrRKi8fiijRg2NRfZaQmmY/nlvivbolPLJo16DBY6EVnWbb0zkNokEs8szcP3++y9UuNtpzMa/RgsdCKytKuzUnF1VqrpGLbAD0WJiByChU5E5BAsdCIih2ChExE5BAudiMghWOhERA7BQicicggWOhGRQwTtxiIRuQnAERHZd85LCQDOt6r9uduTARxppHh1uVDGxn6f+u5f134Xe72+v/8X2mZqXEyNSUN+ja/jYtcxAQIzLlYck4u9FoxxaV2vvVQ1KD8AzPBnOwBvsLLWN2Njv099969rv4u93pBxucA2I+NiakyCMS52HZNAjYsVx8Qu4xLMSy4fBWi7CYHK0tD3qe/+de13sdcb8vvPMWnYr/F1XOw6JkBg8lhxTC72mmXGRWr/5bA8EfGqqsd0DvpXHBfr4ZhYUzDGxU4fis4wHYDOi+NiPRwTa2r0cbHNGToREV2cnc7QiYjoIljoREQOwUInInII2xa6iLQVkddEZL7pLHSWiAwVkZki8oGIXG86D50lIp1EZLqIzBeRSabz0FkiEisia0RkSKDe01KFLiKvi0ihiGw6Z/sgEdkmIjtF5DEAUNXdqjrOTNLQ0cAxeV9V7wNwD4BRBuKGjAaOS56qTgRwGwBOZ2wkDRmTWv8O4L1AZrBUoQOYDWDQTzeIiBvAKwBuANAZwGgR6Rz8aCFrNho+Jk/Uvk6NZzYaMC4icjOAbwF8EdyYIWU26jkmIjIQwBYAhwMZwFKFrqrLAZz7aO8+AHbWnpFXAngHwC1BDxeiGjImctafAXysqmuDnTWUNPTviqp+qKo5AO4MbtLQ0cAxuQZAPwB3ALhPRALSxUFbnMsPaQAO/OT7fAB9RaQZgD8B6CEij6vqs0bShabzjgmAnwMYCCBBRNqr6nQT4ULYhf6uXA1gOIBIAEsN5Apl5x0TVX0QAETkHgBHVLUmEAezQ6HLebapqh4FMDHYYQjAhcfkJQAvBTsM/dOFxuVrAF8HNwrVOu+Y/PML1dmBPJilLrlcQD6AjJ98nw7gR0NZ6CyOiTVxXKwnqGNih0L/HsClItJGRCIA3A7gQ8OZQh3HxJo4LtYT1DGxVKGLyFwAKwFkiUi+iIxT1SoADwL4FEAegPdUdbPJnKGEY2JNHBfrscKYcHEuIiKHsNQZOhER+Y6FTkTkECx0IiKHYKETETkEC52IyCFY6EREDsFCJyJyCBY6EZFDsNCJiBzifwDeHbFri0A+YgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(l1_penalty, non_zeros)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Quiz Question***: What values did you find for l1_penalty_min and l1_penalty_max?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring narrower range of l1_penalty\n",
    "\n",
    "We now explore the region of l1_penalty we found: between `l1_penalty_min` and `l1_penalty_max`. We look for the L1 penalty in this range that produces exactly the right number of nonzeros and also minimizes RSS on the VALIDATION set.\n",
    "\n",
    "For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "\n",
    "* Fit a regression model with a given l1_penalty on TRAIN data. As before, use `alpha=l1_penalty` and `normalize=True`.\n",
    "* Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that has the lowest RSS on the VALIDATION set and has sparsity equal to `max_nonzeros`. (Again, take account of the intercept when counting the number of nonzeros.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty = np.linspace(l1_penalty_min,l1_penalty_max,20)\n",
    "\n",
    "def find_final_l1_penalty(l1_penalty, training, validation, all_features, max_nonzeros):\n",
    "    non_zeros_final = []\n",
    "    rss_validation = []\n",
    "    lowest_rss_final = None\n",
    "    lowest_rss_index = None\n",
    "    lowest_rss_model_coefs = None\n",
    "\n",
    "    for i in range(len(l1_penalty)):\n",
    "        model = linear_model.Lasso(alpha=l1_penalty[i], normalize=True)\n",
    "        model.fit(X=training.loc[:, all_features], y=training['price'])\n",
    "        non_zeros_final.append(np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_))\n",
    "        pred_y = model.predict(X=validation.loc[:, all_features])\n",
    "        rss_validation.append(np.sum((pred_y - validation['price']) ** 2))\n",
    "\n",
    "        if non_zeros_final[i] == max_nonzeros:\n",
    "            if lowest_rss_final is None or rss_validation[i] < lowest_rss_final:\n",
    "                lowest_rss_final = rss_validation[i]\n",
    "                lowest_rss_index = i\n",
    "                lowest_rss_model_coefs = model.coef_\n",
    "                \n",
    "    return (lowest_rss_final, l1_penalty[lowest_rss_index], lowest_rss_model_coefs)\n",
    "\n",
    "lowest_rss_final, final_l1_penalty, final_model_coefs = find_final_l1_penalty(l1_penalty, training, validation, all_features, max_nonzeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Quiz Question***: What value of l1_penalty in our narrow range has the lowest RSS on the VALIDATION set and has sparsity equal to ‘max_nonzeros’?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.11\n"
     ]
    }
   ],
   "source": [
    "print(round(final_l1_penalty,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Quiz Question***: What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True, False, False, False, False, False,\n",
       "        True,  True, False,  True, False, False,  True, False])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_array = (final_model_coefs != 0)\n",
    "filter_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bedrooms', 'bedrooms_square', 'bathrooms', 'sqft_living',\n",
       "       'sqft_living_sqrt', 'sqft_lot', 'sqft_lot_sqrt', 'floors',\n",
       "       'floors_square', 'waterfront', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bathrooms', 'sqft_living', 'waterfront', 'view', 'grade',\n",
       "       'yr_built'], dtype='<U16')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_all_features[filter_array]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
